async def forward_168(self, taskInfo):
    from collections import Counter
    print("Task Requirement: ", taskInfo)
    sub_tasks = []
    agents = []
    logs = []
    
    cot_instruction_1 = (
        "Sub-task 1: Analyze the original nuclear decay process 2A -> 2B + 2E + 2V to identify the roles and properties of each emitted particle, "
        "explicitly emphasizing that the neutrinos V are much lighter but have a small nonzero mass. Characterize why the total energy spectrum of the E particles is continuous and understand the significance of the endpoint energy Q in this context."
    )
    cot_agent_1 = LLMAgentBase(["thinking", "answer"], "Chain-of-Thought Agent", model=self.node_model, temperature=0.0)
    subtask_desc1 = {
        "subtask_id": "subtask_1",
        "instruction": cot_instruction_1,
        "context": ["user query"],
        "agent_collaboration": "CoT"
    }
    thinking1, answer1 = await cot_agent_1([taskInfo], cot_instruction_1, is_sub_task=True)
    agents.append(f"CoT agent {cot_agent_1.id}, analyzing original decay, thinking: {thinking1.content}; answer: {answer1.content}")
    sub_tasks.append(f"Sub-task 1 output: thinking - {thinking1.content}; answer - {answer1.content}")
    subtask_desc1['response'] = {
        "thinking": thinking1,
        "answer": answer1
    }
    logs.append(subtask_desc1)
    print("Step 1: ", sub_tasks[-1])
    
    cot_sc_instruction_2 = (
        "Sub-task 2: Characterize the exotic particle M introduced in the variant decay, explicitly noting that M is exactly massless. "
        "Understand how replacing the two neutrinos V (light but massive) with one massless particle M changes the decay kinematics and energy distribution constraints, "
        "particularly focusing on how this affects the maximum available energy for the E particles."
    )
    N = self.max_sc
    cot_agents_2 = [LLMAgentBase(["thinking", "answer"], "Chain-of-Thought Agent", model=self.node_model, temperature=0.5) for _ in range(N)]
    possible_answers_2 = []
    thinkingmapping_2 = {}
    answermapping_2 = {}
    subtask_desc2 = {
        "subtask_id": "subtask_2",
        "instruction": cot_sc_instruction_2,
        "context": ["user query", "thinking of subtask 1", "answer of subtask 1"],
        "agent_collaboration": "SC_CoT"
    }
    for i in range(N):
        thinking2, answer2 = await cot_agents_2[i]([taskInfo, thinking1, answer1], cot_sc_instruction_2, is_sub_task=True)
        agents.append(f"CoT-SC agent {cot_agents_2[i].id}, characterizing exotic particle M, thinking: {thinking2.content}; answer: {answer2.content}")
        possible_answers_2.append(answer2.content)
        thinkingmapping_2[answer2.content] = thinking2
        answermapping_2[answer2.content] = answer2
    most_common_answer_2 = Counter(possible_answers_2).most_common(1)[0][0]
    thinking2 = thinkingmapping_2[most_common_answer_2]
    answer2 = answermapping_2[most_common_answer_2]
    sub_tasks.append(f"Sub-task 2 output: thinking - {thinking2.content}; answer - {answer2.content}")
    subtask_desc2['response'] = {
        "thinking": thinking2,
        "answer": answer2
    }
    logs.append(subtask_desc2)
    print("Step 2: ", sub_tasks[-1])
    
    cot_reflect_instruction_3 = (
        "Sub-task 3: Determine how the replacement of the two neutrinos V by a single exactly massless particle M affects the total energy spectrum of the outgoing E particles. "
        "Analyze whether the spectrum remains continuous or becomes discrete, and carefully evaluate how the endpoint energy shifts, considering both the mass difference and the number of emitted particles."
    )
    cot_agent_3 = LLMAgentBase(["thinking", "answer"], "Chain-of-Thought Agent", model=self.node_model, temperature=0.0)
    critic_agent_3 = LLMAgentBase(["feedback", "correct"], "Critic Agent", model=self.node_model, temperature=0.0)
    N_max = self.max_round
    cot_inputs_3 = [taskInfo, thinking1, answer1, thinking2, answer2]
    subtask_desc3 = {
        "subtask_id": "subtask_3",
        "instruction": cot_reflect_instruction_3,
        "context": ["user query", "thinking of subtask 1", "answer of subtask 1", "thinking of subtask 2", "answer of subtask 2"],
        "agent_collaboration": "Reflexion"
    }
    thinking3, answer3 = await cot_agent_3(cot_inputs_3, cot_reflect_instruction_3, 0, is_sub_task=True)
    agents.append(f"Reflexion CoT agent {cot_agent_3.id}, analyzing spectrum modification, thinking: {thinking3.content}; answer: {answer3.content}")
    for i in range(N_max):
        feedback, correct = await critic_agent_3([taskInfo, thinking3, answer3], "please review the spectrum modification analysis and provide its limitations.", i, is_sub_task=True)
        agents.append(f"Critic agent {critic_agent_3.id}, providing feedback, thinking: {feedback.content}; answer: {correct.content}")
        if correct.content == "True":
            break
        cot_inputs_3.extend([thinking3, answer3, feedback])
        thinking3, answer3 = await cot_agent_3(cot_inputs_3, cot_reflect_instruction_3, i + 1, is_sub_task=True)
        agents.append(f"Reflexion CoT agent {cot_agent_3.id}, refining spectrum modification, thinking: {thinking3.content}; answer: {answer3.content}")
    sub_tasks.append(f"Sub-task 3 output: thinking - {thinking3.content}; answer - {answer3.content}")
    subtask_desc3['response'] = {
        "thinking": thinking3,
        "answer": answer3
    }
    logs.append(subtask_desc3)
    print("Step 3: ", sub_tasks[-1])
    
    debate_instruction_4a = (
        "Sub-task 4a: Synthesize the physical conclusions from Sub-task 3 regarding the continuity of the spectrum and the direction of the endpoint energy shift. "
        "Use a structured debate approach with two agents: one arguing that the endpoint remains unchanged, and the other arguing that the endpoint increases, based on the mass assumptions and decay kinematics."
    )
    debate_agents_4a = [
        LLMAgentBase(["thinking", "answer"], "Debate Agent", model=self.node_model, role=role, temperature=0.5) 
        for role in self.debate_role
    ]
    N_max_4a = self.max_round
    all_thinking4a = [[] for _ in range(N_max_4a)]
    all_answer4a = [[] for _ in range(N_max_4a)]
    subtask_desc4a = {
        "subtask_id": "subtask_4a",
        "instruction": debate_instruction_4a,
        "context": ["user query", "thinking of subtask 3", "answer of subtask 3"],
        "agent_collaboration": "Debate"
    }
    for r in range(N_max_4a):
        for i, agent in enumerate(debate_agents_4a):
            if r == 0:
                thinking4a, answer4a = await agent([taskInfo, thinking3, answer3], debate_instruction_4a, r, is_sub_task=True)
            else:
                input_infos_4a = [taskInfo, thinking3, answer3] + all_thinking4a[r-1] + all_answer4a[r-1]
                thinking4a, answer4a = await agent(input_infos_4a, debate_instruction_4a, r, is_sub_task=True)
            agents.append(f"Debate agent {agent.id}, round {r}, debating endpoint shift, thinking: {thinking4a.content}; answer: {answer4a.content}")
            all_thinking4a[r].append(thinking4a)
            all_answer4a[r].append(answer4a)
    final_decision_agent_4a = LLMAgentBase(["thinking", "answer"], "Final Decision Agent", model=self.node_model, temperature=0.0)
    thinking4a, answer4a = await final_decision_agent_4a([taskInfo] + all_thinking4a[-1] + all_answer4a[-1], "Sub-task 4a: Make final decision on the physical conclusion about spectrum continuity and endpoint shift.", is_sub_task=True)
    agents.append(f"Final Decision agent, making physical conclusion, thinking: {thinking4a.content}; answer: {answer4a.content}")
    sub_tasks.append(f"Sub-task 4a output: thinking - {thinking4a.content}; answer - {answer4a.content}")
    subtask_desc4a['response'] = {
        "thinking": thinking4a,
        "answer": answer4a
    }
    logs.append(subtask_desc4a)
    print("Step 4a: ", sub_tasks[-1])
    
    options_text = (
        "A) The spectrum becomes discrete, and the endpoint increases.\n"
        "B) The spectrum remains continuous with an adjusted shape, and the endpoint decreases.\n"
        "C) The spectrum remains continuous with an adjusted shape, and the endpoint increases.\n"
        "D) The spectrum becomes discrete, and the endpoint decreases."
    )
    
    debate_instruction_4b = (
        "Sub-task 4b: Map the physical conclusion from Sub-task 4a to the closest matching multiple-choice option (A, B, C, or D). "
        "If no option exactly matches the conclusion, select the closest option and explicitly justify the choice, ensuring compliance with the output format requiring a single letter answer. "
        "Include the full set of options in the context to enable direct comparison."
    )
    debate_agents_4b = [
        LLMAgentBase(["thinking", "answer"], "Debate Agent", model=self.node_model, role=role, temperature=0.5) 
        for role in self.debate_role
    ]
    N_max_4b = self.max_round
    all_thinking4b = [[] for _ in range(N_max_4b)]
    all_answer4b = [[] for _ in range(N_max_4b)]
    subtask_desc4b = {
        "subtask_id": "subtask_4b",
        "instruction": debate_instruction_4b,
        "context": ["user query", "physical conclusion from subtask 4a", "multiple-choice options", options_text],
        "agent_collaboration": "Debate"
    }
    for r in range(N_max_4b):
        for i, agent in enumerate(debate_agents_4b):
            if r == 0:
                thinking4b, answer4b = await agent([taskInfo, thinking4a, answer4a, options_text], debate_instruction_4b, r, is_sub_task=True)
            else:
                input_infos_4b = [taskInfo, thinking4a, answer4a, options_text] + all_thinking4b[r-1] + all_answer4b[r-1]
                thinking4b, answer4b = await agent(input_infos_4b, debate_instruction_4b, r, is_sub_task=True)
            agents.append(f"Debate agent {agent.id}, round {r}, mapping conclusion to options, thinking: {thinking4b.content}; answer: {answer4b.content}")
            all_thinking4b[r].append(thinking4b)
            all_answer4b[r].append(answer4b)
    final_decision_agent_4b = LLMAgentBase(["thinking", "answer"], "Final Decision Agent", model=self.node_model, temperature=0.0)
    thinking4b, answer4b = await final_decision_agent_4b([taskInfo] + all_thinking4b[-1] + all_answer4b[-1], "Sub-task 4b: Make final decision on the multiple-choice answer selection.", is_sub_task=True)
    agents.append(f"Final Decision agent, selecting final answer option, thinking: {thinking4b.content}; answer: {answer4b.content}")
    sub_tasks.append(f"Sub-task 4b output: thinking - {thinking4b.content}; answer - {answer4b.content}")
    subtask_desc4b['response'] = {
        "thinking": thinking4b,
        "answer": answer4b
    }
    logs.append(subtask_desc4b)
    print("Step 4b: ", sub_tasks[-1])
    
    final_answer = await self.make_final_answer(thinking4b, answer4b, sub_tasks, agents)
    return final_answer, logs