[
    {
        "example_id": 104,
        "problem": [
            "Astronomers are currently observing a star with a radius equal to that of the Sun. One  hemisphere of the star is covered in dark spots with a filling factor of 20%. The star has an effective temperature (Teff) of 6000K, and the spots exhibit a temperature difference of 1000K. As only one hemisphere is spotty, photometric time-series observations will reveal periodic variations in brightness due to rotational modulation. Interestingly, this situation can closely resemble the presence of an exoplanet. To produce the same amplitude signal in the star's light curve (if the star was not covered by spots!), what should be the radius of a hypothetical exoplanet relative to the radius of the host star (i.e. Rpl/Rstar)?",
            "~0.07",
            "~0.32",
            "~0.11",
            "~0.39",
            2
        ],
        "correct_answer": 2,
        "n": "Baseline debate",
        "response": "The flux from the unspotted hemisphere scales as Teff^4. For Teff=6000K we set F_un=1. The spotted hemisphere flux is F_sp=0.8\u00b71 + 0.2\u00b7(5000/6000)^4 = 0.8 + 0.2\u00b7(625/1296) \u2248 0.89645. The relative drop \u0394F/F = 1\u22120.89645 \u2248 0.10355. If this were due to a transit, depth=(Rpl/Rstar)^2=0.10355 \u21d2 Rpl/Rstar\u2248\u221a0.10355\u22480.32.\n\nAnswer:B)",
        "sub_tasks_text": null
    }
]